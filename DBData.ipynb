{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = './dblp-ref-0.json'\n",
    "lines = []\n",
    "with open(filename) as file:\n",
    "    for line in file:\n",
    "        lines.append(line.rstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "obj = json.loads(lines[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'authors': ['Tegegne Marew', 'Doo-Hwan Bae'],\n",
       " 'id': '01f1d231-80ae-4cce-b56c-9d821e0924d0',\n",
       " 'n_citation': 1,\n",
       " 'references': ['2134bf3b-fd89-4724-90ce-5993b4fa3218',\n",
       "  '906c17e0-db09-407b-b760-41df5a3f0293',\n",
       "  '94f4382e-cfa6-4aec-92b8-3711fc55da54',\n",
       "  '9f172585-8d42-4fce-b6ae-aede321f3fd4',\n",
       "  'a3aee287-efd0-4b9d-9cda-d47dd192c9f4',\n",
       "  'a9a7fd07-ef71-4b3c-8fcf-d7fe114d2148',\n",
       "  'd63dd4ae-4b30-484b-8ffc-88d21839ddad'],\n",
       " 'title': 'Using Classpects for Integrating Non-Functional and Functional Requirements.',\n",
       " 'venue': 'international conference on software engineering',\n",
       " 'year': 2006}"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "authors_list = []\n",
    "venues_list = []\n",
    "articles_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for l in lines :\n",
    "    obj = json.loads(l)\n",
    "    for a in obj['authors']:\n",
    "        authors_list.append(a)\n",
    "    if obj.get('references'):\n",
    "        for r in obj['references']:\n",
    "            articles_list.append(r)\n",
    "\n",
    "    venues_list.append(obj['venue'].replace(',','.'))\n",
    "    articles_list.append(obj['id'].replace(',','.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Content for the NODES files\n",
    "authors = list(set(authors_list))\n",
    "venues = list(set(venues_list))\n",
    "articles = list(set(articles_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "author_article = []\n",
    "article_venue = []\n",
    "article_article = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in lines :\n",
    "    obj = json.loads(l)\n",
    "    article_venue.append(obj['id'] + ','+ obj['venue'].replace(',','.'))\n",
    "    if obj.get('references'):\n",
    "        for r in obj['references']:\n",
    "            article_article.append(obj['id'] + ',' + r)\n",
    "    if obj.get('authors'):\n",
    "        for a in obj['authors']:\n",
    "            author_article.append(a.replace(',','.') + ',' + obj['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df = pandas.DataFrame(data={\"id\": articles})\n",
    "#df.to_csv(\"./articles.csv\", sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df = pandas.DataFrame(data={\"name\": authors})\n",
    "#df.to_csv(\"./authors.csv\", sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./Data/authors.csv','w') as result_file:\n",
    "    wr = csv.writer(result_file)\n",
    "    for item in authors:\n",
    "        str(item).replace(',','#')\n",
    "        wr.writerow([item.replace(',','.'), 'AUTHOR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./Data/articles.csv','w') as result_file:\n",
    "    wr = csv.writer(result_file, dialect='excel')\n",
    "    for item in articles:\n",
    "        #x = item.split(',')\n",
    "        wr.writerow([item, 'ARTICLE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./Data/venues.csv','w') as result_file:\n",
    "    wr = csv.writer(result_file, dialect='excel')\n",
    "    for item in venues:\n",
    "        #x = item.split(',')\n",
    "        wr.writerow([item.replace(',','.'), 'VENUE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Data/article_author.csv','w') as result_file:\n",
    "    wr = csv.writer(result_file, dialect='excel')\n",
    "    for item in author_article:\n",
    "        x = item.split(',')\n",
    "        wr.writerow([x[1], x[0], 'ARTICLE_AUTHOR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./Data/article_venue.csv','w') as result_file:\n",
    "    wr = csv.writer(result_file, dialect='excel')\n",
    "    for item in article_venue:\n",
    "        x = item.split(',')\n",
    "        wr.writerow([x[0], x[1], 'ARTICLE_VENUE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./Data/article_article.csv','w') as result_file:\n",
    "    wr = csv.writer(result_file, dialect='excel')\n",
    "    for item in article_article:\n",
    "        x = item.split(',')\n",
    "        wr.writerow([x[0], x[1], 'ARTICLE_ARTICLE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'01f1d231-80ae-4cce-b56c-9d821e0924d0,2134bf3b-fd89-4724-90ce-5993b4fa3218'"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_article[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
